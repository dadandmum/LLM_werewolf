
\section{Background}
In this section, we will preliminarily outline the developmental history of large-language-model-based agents(\S\ref{sec:llm_agent}) and the relevant research in werewolf-like communication game(\S\ref{sec:llm_agent_social_game}), while we will also explain why we chose "One Night Ultimate Werewolf" as the platform for our experiment. Moreover, we will discuss personality trait analysis in psychology and justify the selection of the Big Five personality traits as the basis for classifying agent characteristics(\S\ref{sec:big_five_trait}), as well as some relevant studies involving the combination between personality traits and LLM agent (\S\ref{sec:big_five_llm}).

\subsection{Agents based on Large Language Models} \label{sec:llm_agent}
Currently, there is a trend toward developing larged language model agents for diverse fields, including psycholgy \citep{aher2023using}, social system simulation \citep{gao2023social,zhou2023sotopia}, physical integration \citep{ahn2022can}, social game study \citep{xu2023exploring,wang2023avalon} and cross-agency simulation\citep{park2023generative}. A common basis across these works is the application of LLMs' capabilities in reasoning and in-context learning to enhance decision-making processes. Chain-of-Thought(CoT) \citep{wei2022chain} might be the best-known work that taps into the reasoning abilities of LLMs by prompting them to think through problems step-by-step. Other researchers also proposed different methods to enhance the ability of LLM agent, like generate reasoning traces and task-specific actions in an interleaved manner \citep{yao2022react}, recursive prompting to implement self-refinement \citep{madaan2024self} and decentralized information sharing \citep{zhang2023building}. Moreover, Tree-of-Thought (ToT) \citep{yao2024tree}, which generalized CoT by generating multiple thoughts at each steop of reasoning process to form a tree-like structure and enable the search for optimal plans, and LLM+P \citep{liu2023llm+}, which integrates classic planners by translating natural language task descriptions into Planning Domain Definition Language(PDDL), have been introduced. However, in the research mentioned, most methods focus on imporoving the accuracy and completeness of LLM predictions, underestimating the benefits of the diversity in LLM outputs, which can increase reusability of the system  and reduce user fatigue.


\subsection{LLM agent in incomplete information social game} \label{sec:llm_agent_social_game}

Social deduction game, which can also be known as incomplete information game, such as Werewolf, Avalon and ONUW,  rely heavily on communication skills and strategic thinking. An ε-Nash equilibrium is studied to detect the winning rate in werewolf game \citep{bi2016human}. DeepRole \citep{serrino2019finding} integrates deductive reasoning into vector-form counterfactual regret minimization (CFR) to improve AI performance in the five-player Avalon game. In the field of LLM, various frameworks are suggested to simulate and enhance the game experience of werewolf-like game. An external Thinker module is illustrated to enhance the reasoning abilities of LLM agents \citep{wu2024enhance}. An RL-instructed language agent framework for ONUW is demostrated based on the existence of the Perfect Bayesian Equilibria(PBEs) \citep{jin2024learning}. Historical infomation is significantly considered in building a tuning-free LLM framework \citep{xu2023exploring}. Another research introduces ReCon to demostrate the ability of LLM agents to find out deceptive infomation in Avalon game. Despite their creative and rigorous framework designs, their evaluation of LLM agent-generated content tends to focus heavily on the ability to win games, for example, whether it can make correct votes through logical reasoning. In our design, winning the game will no longer be considered the sole criterion. Instead, we will place greater emphasis on whether the AI system can generate sufficiently engaging, diverse, and non-repetitive content, which is quantified through our evaluations.


\subsection{Big Five Personality Model} \label{sec:big_five_trait}


Personality encompasses the distinctive psychological traits that shape an individual's behaviors, thoughts, and emotions across different situations and over time \citep{roberts2000rank}. The Big Five is a well-established model for persoanlity trait measurement in the field of personality psychology \citep{john2008paradigm}. In its theory, many significant variations in how people think, feel, and behave can be effectively summarized by the Big Five personality domains, which are labeled as Extraversion, Agreeableness, Conscientiousness, Neuroticism and Openness to Experience \citep{costa1999five}. The five-factor model(FFM) is a variation to the Big Five framework. Contrast to the Big Five framework, the FFM is grounded in empirical analyses of questionnaire data. Costa Jr and McCrae \citep{costa1976age} summrized the 16 personality factors \citep{cattell1992handbook} and identified three inital domains: Neuroticism, Extraversion, and Openness. Later, they added another two factors, Agreeableness and conscientiousness, resulting in five factors that closely resembled the domains of the Big Five framework \citep{mccrae1987validation}. Several scales are aviablable for measuring the Five Factor Model(FFM) domains, including the 240-item Revised NEO Personality Inventory \citep{mccrae1991neo,costa2008revised}, 60-item NEO Five Factory Inventory \citep{mccrae1989neo,mccrae2004contemplated}, the International Personality Item Pool \citep{goldberg2006international}. In our research, we collected adjective definers of the Five Factors \citep{mccrae2004contemplated} and the questionnaire items from IPIP \citep{goldberg2006international} as the database for our LLM agent persona implementaion. 

\subsection{Big Five in LLM} \label{sec:big_five_llm}

Research related to personality traits and LLM agents has recently become a hot topic in academic circles. Some researchers have employed the Big Five personality model to analyze popular LLM frameworks, examining their score of five factors \citep{karra2022estimating,caron2022identifying}; other scholars have opted for the Myers–Briggs Type Indicator(MBTI) model \citep{pan2023llms}. These studies provide positive evidence for the manifestation of personality characteristics in LLM agents. Moreover, LLMs may also display potentially harmful dark personality patterns, leading to discussions about psychological safety; as a result, some models for assessing the safety of LLMs have been proposed \citep{li2022does}. Furthermore, researchers \citep{safdari2023personality} have demonstrated the potential for introducing different personality traits in LLMs, meaning that with precise technical optimization, LLMs with specific personality traits can be produced. "Social Simulacra" is a proposed prompt-building framework that incorporates concise summaries encompassing desired personality traits, interests, or other attributes \citep{park2022social}. These studies highlight the potential of large language models to mimic the personalities of different human types.
